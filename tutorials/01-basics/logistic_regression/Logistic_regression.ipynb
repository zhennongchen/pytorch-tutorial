{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28    # 784\n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,batch_size = batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "image1, label1 = train_dataset[0]\n",
    "print(image1.size())\n",
    "data_iter = iter(train_loader)\n",
    "images,labels = data_iter.next()\n",
    "print(images.size())\n",
    "print(labels.size())\n",
    "print(train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "a = list(image1.size())[1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = nn.Linear(list(image1.size())[1] * list(image1.size())[2],num_classes)\n",
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 0, batch 100, the loss is 2.2381\n",
      "at epoch 0, batch 200, the loss is 2.1380\n",
      "at epoch 0, batch 300, the loss is 2.0250\n",
      "at epoch 0, batch 400, the loss is 1.9213\n",
      "at epoch 0, batch 500, the loss is 1.8790\n",
      "at epoch 0, batch 600, the loss is 1.7547\n",
      "at epoch 1, batch 100, the loss is 1.7298\n",
      "at epoch 1, batch 200, the loss is 1.6654\n",
      "at epoch 1, batch 300, the loss is 1.6129\n",
      "at epoch 1, batch 400, the loss is 1.6108\n",
      "at epoch 1, batch 500, the loss is 1.5847\n",
      "at epoch 1, batch 600, the loss is 1.5392\n",
      "at epoch 2, batch 100, the loss is 1.4461\n",
      "at epoch 2, batch 200, the loss is 1.3515\n",
      "at epoch 2, batch 300, the loss is 1.3626\n",
      "at epoch 2, batch 400, the loss is 1.3521\n",
      "at epoch 2, batch 500, the loss is 1.2627\n",
      "at epoch 2, batch 600, the loss is 1.2362\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for epoch in range(0,num_epochs):\n",
    "    \n",
    "    for batch_index , data in enumerate(train_loader,0):\n",
    "        \n",
    "        \n",
    "        # get data\n",
    "        images , labels = data\n",
    "        \n",
    "        # currently images (one channel) has dimension as (batch_size,1,input_size[0],input_size[1])\n",
    "        # we need to reshape it so its dimension is (batch_size,inputisze[0],inputsize[1])\n",
    "        images = images.reshape(-1, list(image1.size())[1] * list(image1.size())[2])\n",
    "        \n",
    "        \n",
    "        # zero buffer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # get the loss print\n",
    "        \n",
    "        if batch_index % 100 == 99:\n",
    "            print('at epoch %d, batch %d, the loss is %.4f' % (epoch, batch_index + 1, round(loss.item() ,4)))\n",
    "            total_loss = 0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Save the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "weight \t torch.Size([10, 784])\n",
      "bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "    \n",
    "# save the checkpoint of the model - which can be used to resume the training\n",
    "PATH = 'logistic_regression_example.ckpt'\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST THE MODEL\n",
    "net = nn.Linear(list(image1.size())[1] * list(image1.size())[2],num_classes)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is %.4f 0.7992\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_num, data in enumerate(test_loader,0):\n",
    "        images, labels = data\n",
    "        images = images.reshape(-1, input_size)\n",
    "        \n",
    "        # outputs\n",
    "        outputs = net(images)\n",
    "        \n",
    "        # get the maximum\n",
    "        outputs_m = torch.argmax(outputs.data,1)\n",
    "        \n",
    "        correct += sum(outputs_m == labels).item()\n",
    "        \n",
    "        total += list(outputs.size())[0]\n",
    "        \n",
    "    print('accuracy is %.4f', correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
